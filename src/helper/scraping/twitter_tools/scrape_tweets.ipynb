{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Working with the API within a Python program is straightforward for the v2 client.\n",
    "\n",
    "We'll assume that credentials are in the default location, `~/.twitter_keys.yaml`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from searchtweets import ResultStream, gen_request_parameters, load_credentials, collect_results\n",
    "import pandas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_list(lst, num_chunks):\n",
    "    chunk_size = len(lst) // num_chunks\n",
    "    chunks = []\n",
    "    for i in range(0, len(lst), chunk_size):\n",
    "        chunks.append(lst[i:i + chunk_size])\n",
    "    last_chunk_size = len(lst) % num_chunks\n",
    "    if last_chunk_size != 0:\n",
    "        last_chunk = lst[-last_chunk_size:]\n",
    "        chunk_counter = 0\n",
    "        for remainder_last_chunk in last_chunk:\n",
    "            chunks[chunk_counter].append(remainder_last_chunk)\n",
    "            chunk_counter += 1\n",
    "    return chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_list = list(range(1315282))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_list = split_list(original_list,(len(original_list)//350000)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(mod_list[0]),len(mod_list[1]),len(mod_list[2]), len(mod_list[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(mod_list[0])+len(mod_list[1])+len(mod_list[2])+len(mod_list[3])+len(mod_list[4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mod_list[0],mod_list[1],mod_list[2], mod_list[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## v2 setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "v2_search_args = load_credentials(\"~/.twitter_keys.yaml\",\n",
    "                                          yaml_key=\"count_tweets_v2\",\n",
    "                                          env_overwrite=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_rule = gen_request_parameters(\"(#Ukraine OR #Ukrainian) (#refugee OR #refugees OR #migration OR #migrants OR #migrant OR #flüchtlinge)  (place_country:CH OR place_country:UA)\",\n",
    "                                    granularity=\"day\",\n",
    "                                    #end_time=\"2022-11-10\",\n",
    "                                    start_time=\"2022-02-24\")\n",
    "\n",
    "# bounding_box:[west_long south_lat east_long north_lat] bounding_box:[-105.301758 39.964069 -105.178505 40.09455]\n",
    "\n",
    "counts = collect_results(count_rule, result_stream_args=v2_search_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Read the data from the JSON file\n",
    "with open(\"../../data/twitter/EU/EU_count.json\") as f:\n",
    "    data = f.readlines()\n",
    "\n",
    "# Count the tweet_count values\n",
    "tweet_count = 0\n",
    "for line in data:\n",
    "    try:\n",
    "        tweet_count += sum(item['tweet_count'] for item in json.loads(line)['data'])\n",
    "    except json.decoder.JSONDecodeError:\n",
    "        continue\n",
    "print(\"Total tweet count:\", tweet_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"../../data/twitter/results/tweets.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates([\"text\"]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates([\"text\"]).text.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = {\"data\": [{\"created_at\": \"2023-01-30T20:31:45.000Z\", \"edit_history_tweet_ids\": [\"1620157844762017792\"], \"id\": \"1620157844762017792\", \"text\": \"RT @Schmitt_News: \\u00d6sterreich hilft der #Ukraine mit:\\n- 80 Mio. \\u20ac Steuergeld\\n- 200.000 Liter Diesel\\n- Helmen, Schutzwesten\\n- xx Mio. \\u00fcber EP\\u2026\"}, {\"created_at\": \"2023-01-30T20:31:37.000Z\", \"edit_history_tweet_ids\": [\"1620157809747951616\"], \"id\": \"1620157809747951616\", \"text\": \"RT @Schmitt_News: \\u00d6sterreich hilft der #Ukraine mit:\\n- 80 Mio. \\u20ac Steuergeld\\n- 200.000 Liter Diesel\\n- Helmen, Schutzwesten\\n- xx Mio. \\u00fcber EP\\u2026\"}, {\"created_at\": \"2023-01-30T20:30:39.000Z\", \"edit_history_tweet_ids\": [\"1620157567724040192\"], \"id\": \"1620157567724040192\", \"text\": \"RT @djuric_zlatko: \\u201cMore than 50,000 refugees were admitted to Austria, millions buttered into the EU pot for Ukraine. In return, Kiev is n\\u2026\"}, {\"created_at\": \"2023-01-30T20:28:17.000Z\", \"edit_history_tweet_ids\": [\"1620156971335954432\"], \"id\": \"1620156971335954432\", \"text\": \"RT @Schmitt_News: \\u00d6sterreich hilft der #Ukraine mit:\\n- 80 Mio. \\u20ac Steuergeld\\n- 200.000 Liter Diesel\\n- Helmen, Schutzwesten\\n- xx Mio. \\u00fcber EP\\u2026\"}, {\"created_at\": \"2023-01-30T20:28:01.000Z\", \"edit_history_tweet_ids\": [\"1620156905233739779\"], \"id\": \"1620156905233739779\", \"text\": \"RT @Schmitt_News: \\u00d6sterreich hilft der #Ukraine mit:\\n- 80 Mio. \\u20ac Steuergeld\\n- 200.000 Liter Diesel\\n- Helmen, Schutzwesten\\n- xx Mio. \\u00fcber EP\\u2026\"}, {\"created_at\": \"2023-01-30T20:27:58.000Z\", \"edit_history_tweet_ids\": [\"1620156891388338176\"], \"id\": \"1620156891388338176\", \"text\": \"RT @djuric_zlatko: \\u201cMore than 50,000 refugees were admitted to Austria, millions buttered into the EU pot for Ukraine. In return, Kiev is n\\u2026\"}, {\"created_at\": \"2023-01-30T20:27:52.000Z\", \"edit_history_tweet_ids\": [\"1620156865584979968\"], \"id\": \"1620156865584979968\", \"text\": \"RT @Schmitt_News: \\u00d6sterreich hilft der #Ukraine mit:\\n- 80 Mio. \\u20ac Steuergeld\\n- 200.000 Liter Diesel\\n- Helmen, Schutzwesten\\n- xx Mio. \\u00fcber EP\\u2026\"}, {\"created_at\": \"2023-01-30T20:25:27.000Z\", \"edit_history_tweet_ids\": [\"1620156257507360768\"], \"id\": \"1620156257507360768\", \"text\": \"RT @Schmitt_News: \\u00d6sterreich hilft der #Ukraine mit:\\n- 80 Mio. \\u20ac Steuergeld\\n- 200.000 Liter Diesel\\n- Helmen, Schutzwesten\\n- xx Mio. \\u00fcber EP\\u2026\"}, {\"created_at\": \"2023-01-30T20:24:17.000Z\", \"edit_history_tweet_ids\": [\"1620155963054632960\"], \"id\": \"1620155963054632960\", \"text\": \"RT @Schmitt_News: \\u00d6sterreich hilft der #Ukraine mit:\\n- 80 Mio. \\u20ac Steuergeld\\n- 200.000 Liter Diesel\\n- Helmen, Schutzwesten\\n- xx Mio. \\u00fcber EP\\u2026\"}, {\"created_at\": \"2023-01-30T20:24:16.000Z\", \"edit_history_tweet_ids\": [\"1620155957681721345\"], \"id\": \"1620155957681721345\", \"text\": \"RT @djuric_zlatko: \\u201cMore than 50,000 refugees were admitted to Austria, millions buttered into the EU pot for Ukraine. In return, Kiev is n\\u2026\"}], \"meta\": {\"newest_id\": \"1620157844762017792\", \"oldest_id\": \"1620155957681721345\", \"result_count\": 10, \"next_token\": \"b26v89c19zqg8o3fqk6z48zfa5845e6v1xykanz0dv1bx\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, count in enumerate(counts):\n",
    "    if index == 0:\n",
    "        total_counts = count[\"meta\"]['total_tweet_count']\n",
    "    else:\n",
    "        total_counts += count[\"meta\"]['total_tweet_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = { #TODO: check all translations\n",
    "\"AT\": {\"de\": [\"Ukraine + Flüchtlinge\", \"Ukraine + flüchten\", \"Ukraine + Migranten\", \"Ukraine + migrieren\", \"Ukraine + Asyl\"]}, #Austria\n",
    "\"BE\": {\"nl\": [\"Ukraine + Vluchtelingen\", \"Ukraine + vluchten\", \"Ukraine + migranten\", \"Ukraine + migreren\", \"Ukraine + asiel\"],\n",
    "       \"fr\": [\"Ukraine + réfugiés\", \"Ukraine + réfugiant\", \"Ukraine + migrants\", \"Ukraine + migrant\", \"Ukraine + asile\"]}, #Belgium\n",
    "\"BG\": {\"bg\": [\"Украйна + бежанци\", \"Украйна + бежи\", \"Украйна + мигранти\", \"Украйна + мигрират\", \"Украйна + асил\"]}, #Bulgaria\n",
    "\"HR\": {\"hr\": [\"Ukrajina + izbjeglice\", \"Ukrajina + izbjegavajući\", \"Ukrajina + migranti\", \"Ukrajina + migrirajući\", \"Ukrajina + azil\"]}, #Croatia\n",
    "\"CY\": {\"el\": [\"Ουκρανία + πρόσφυγες\", \"Ουκρανία + πρόσφυγα\", \"Ουκρανία + μετανάστες\", \"Ουκρανία + μεταναστεύοντας\", \"Ουκρανία + ασύλο\"]}, #Cyprus\n",
    "\"CZ\": {\"cs\": [\"Ukrajina + uprchlíci\", \"Ukrajina + uprchající\", \"Ukrajina + migranti\", \"Ukrajina + migrace\", \"Ukrajina + azyl\"]}, #Czechia\n",
    "\"DK\": {\"da\": [\"Ukraine + flygtninge\", \"Ukraine + flygtede\", \"Ukraine + migrant\", \"Ukraine + migrere\", \"Ukraine + asyl\"]}, #Denmark\n",
    "\"EE\": {\"et\": [\"Ukraina + põgenikud\", \"Ukraina + põgenenud\", \"Ukraina + migrant\", \"Ukraina + migreerima\", \"Ukraina + varjupaik\"]}, #Estonia\n",
    "\"FI\": {\"fi\": [\"Ukraina + pakolaiset\", \"Ukraina + pakenevat\", \"Ukraina + siirtolaiset\", \"Ukraina + siirtolaisten\", \"Ukraina + turvapaikka\"]}, #Finland\n",
    "\"FR\": {\"fr\": [\"Ukraine + réfugiés\", \"Ukraine + réfugiant\", \"Ukraine + migrants\", \"Ukraine + migrant\", \"Ukraine + asile\"]}, #France\n",
    "\"DE\": {\"de\": [\"Ukraine + Flüchtlinge\", \"Ukraine + flüchten\", \"Ukraine + Migranten\", \"Ukraine + migrieren\", \"Ukraine + Asyl\"]}, #Germany\n",
    "\"GR\": {\"el\": [\"Ουκρανία + πρόσφυγες\", \"Ουκρανία + πρόσφυγα\", \"Ουκρανία + μετανάστες\", \"Ουκρανία + μεταναστεύοντας\", \"Ουκρανία + ασύλο\"]}, #Greece\n",
    "\"HU\": {\"hu\": [\"Ukrajna + menekültek\", \"Ukrajna + menekül\", \"Ukrajna + migránsok\", \"Ukrajna + migráns\", \"Ukrajna + menekült\"]}, #Hungary\n",
    "\"IE\": {\"en\": [\"Ukraine + refugees\", \"Ukraine + escape\", \"Ukraine + migrants\", \"Ukraine + migrate\", \"Ukraine + asylum\"]}, #Ireland\n",
    "\"IT\": {\"it\": [\"Ucraina + rifugiati\", \"Ucraina + rifugiato\", \"Ucraina + migranti\", \"Ucraina + migrante\", \"Ucraina + asilo\"]}, #Italy\n",
    "\"LV\": {\"lv\": [\"Ukraina + izglītības\", \"Ukraina + izglītības\", \"Ukraina + migranti\", \"Ukraina + migrēt\", \"Ukraina + azils\"]}, #Latvia\n",
    "\"LT\": {\"lt\": [\"Ukraina + išvykusių\", \"Ukraina + išvykusių\", \"Ukraina + migrantai\", \"Ukraina + migracijos\", \"Ukraina + azilas\"]}, #Lithuania\n",
    "\"LU\": {\"de\": [\"Ukraine + Flüchtlinge\", \"Ukraine + flüchten\", \"Ukraine + Migranten\", \"Ukraine + migrieren\", \"Ukraine + Asyl\"],\n",
    "       \"fr\": [\"Ukraine + réfugiés\", \"Ukraine + réfugiant\", \"Ukraine + migrants\", \"Ukraine + migrant\", \"Ukraine + asile\"]}, #Luxembourg\n",
    "\"MT\": {\"mt\": [\"Ukrajna + refuġjati\", \"Ukrajna + ħarba\", \"Ukrajna + migranti\", \"Ukrajna + jemigraw\", \"Ukrajna + ażil\"],\n",
    "       \"en\": [\"Ukraine + refugees\", \"Ukraine + escape\", \"Ukraine + migrants\", \"Ukraine + migrate\", \"Ukraine + asylum\"]}, #Malta\n",
    "\"NL\": {\"nl\": [\"Ukraine + Vluchtelingen\", \"Ukraine + vluchten\", \"Ukraine + migranten\", \"Ukraine + migreren\", \"Ukraine + asiel\"]}, #Netherlands\n",
    "\"PL\": {\"pl\": [\"Ukraina + uchodźcy\", \"Ukraina + uciekać\", \"Ukraina + migrantów\", \"Ukraina + migracja\", \"Ukraina + azyl\"]}, #Poland\n",
    "\"PT\": {\"pt\": [\"Ucrânia + refugiados\", \"Ucrânia + refugiado\", \"Ucrânia + migrantes\", \"Ucrânia + migrante\", \"Ucrânia + asilo\"]}, #Portugal\n",
    "\"RO\": {\"ro\": [\"Ucraina + refugiați\", \"Ucraina + refugiat\", \"Ucraina + migranți\", \"Ucraina + migranți\", \"Ucraina + azil\"]}, #Romania\n",
    "\"SK\": {\"sk\": [\"Ukrajina + uprchlíci\", \"Ukrajina + uprchajúci\", \"Ukrajina + migranti\", \"Ukrajina + migrácia\", \"Ukrajina + azyl\"]}, #Slovakia\n",
    "\"SI\": {\"sl\": [\"Ukrajina + begunci\", \"Ukrajina + begunec\", \"Ukrajina + migranti\", \"Ukrajina + migracija\", \"Ukrajina + azil\"]}, #Slovenia\n",
    "\"ES\": {\"es\": [\"Ucrania + refugiados\", \"Ucrania + refugiado\", \"Ucrania + migrantes\", \"Ucrania + migrante\", \"Ucrania + asilo\"]}, #Spain\n",
    "\"SE\": {\"sv\": [\"Ukraina + flyktingar\", \"Ukraina + flykting\", \"Ukraina + migranter\", \"Ukraina + migrera\", \"Ukraina + asyl\"]}, #Sweden\n",
    "\"CH\": {\"de\": [\"Ukraine + Flüchtlinge\", \"Ukraine + flüchten\", \"Ukraine + Migranten\", \"Ukraine + migrieren\", \"Ukraine + Asyl\"],\n",
    "       \"fr\": [\"Ukraine + réfugiés\", \"Ukraine + réfugiant\", \"Ukraine + migrants\", \"Ukraine + migrant\", \"Ukraine + asile\"],\n",
    "       \"it\": [\"Ucraina + rifugiati\", \"Ucraina + rifugiato\", \"Ucraina + migranti\", \"Ucraina + migrante\", \"Ucraina + asilo\"]}, #Switzerland\n",
    "\"NO\": {\"no\": [\"Ukraina + flyktninger\", \"Ukraina + flyktet\", \"Ukraina + migranter\", \"Ukraina + migrere\", \"Ukraina + asyl\"]}, #Norway\n",
    "\"GB\": {\"en\": [\"Ukraine + refugees\", \"Ukraine + escape\", \"Ukraine + migrants\", \"Ukraine + migrate\", \"Ukraine + asylum\"]}, #United Kingdom\n",
    "\"LI\": {\"de\": [\"Ukraine + Flüchtlinge\", \"Ukraine + flüchten\", \"Ukraine + Migranten\", \"Ukraine + migrieren\", \"Ukraine + Asyl\"]}, #Liechtenstein\n",
    "\"IS\": {\"is\": [\"Úkraína + flyktingar\", \"Úkraína + flykting\", \"Úkraína + flyktingar\", \"Úkraína + flyktingar\", \"Úkraína + flyktingar\"]}, #Iceland\n",
    "\"MD\": {\"ro\": [\"Ucraina + refugiați\", \"Ucraina + refugiat\", \"Ucraina + migranți\", \"Ucraina + migranți\", \"Ucraina + azil\"]}, #Moldova\n",
    "\"UA\": {\"uk\": [\"Україна + біженці\", \"Україна + біженець\", \"Україна + мігранти\", \"Україна + міграція\", \"Україна + азіл\"]}, #Ukraine\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string='''\n",
    "(Ukraine OR Ukrainian) \n",
    "(refugee OR refugees OR migration OR migrants OR migrant)\n",
    "(Austria OR Belgium OR Bulgaria OR Croatia OR Cyprus OR Czechia OR Denmark \n",
    "OR Estonia OR Finland OR France OR Germany OR Greece OR Hungary OR Ireland OR Italy \n",
    "OR Latvia OR Lithuania OR Luxembourg OR Malta OR Netherlands OR Poland OR Portugal \n",
    "OR Romania OR Slovakia OR Slovenia OR Spain OR Sweden OR Switzerland OR Norwegia OR \n",
    "(United Kingdom) OR Liechtenstein OR Iceland OR Moldova) \n",
    "'''   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a function that formats search API rules into valid json queries called `gen_request_parameters`. It has sensible defaults, such as pulling more Tweets per call than the default 10 and not including dates. Discussing the finer points of generating search rules is out of scope for these examples; I encourage you to see the docs to learn the nuances within, but for now let's see what a rule looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = gen_request_parameters(\"beyonce\", results_per_call=10, granularity=None) # testing with a sandbox account\n",
    "print(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This query will match tweets that have the text `beyonce` in them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this point, there are two ways to interact with the API. There is a quick method to collect smaller amounts of Tweets to memory that requires less thought and knowledge, and interaction with the `ResultStream` object which will be introduced later.\n",
    "\n",
    "\n",
    "## Fast Way\n",
    "\n",
    "We'll use the `search_args` variable to power the configuration point for the API. The object also takes a valid query and has options to cutoff search when hitting limits on both number of Tweets and API calls.\n",
    "\n",
    "We'll be using the `collect_results` function, which has three parameters.\n",
    "\n",
    "- query: a valid search query, referenced earlier\n",
    "- max_results: as the API handles pagination, it will stop collecting when we get to this number\n",
    "- result_stream_args: configuration args that we've already specified.\n",
    "\n",
    "\n",
    "For the remaining examples, please change the args to either premium or enterprise depending on your usage.\n",
    "\n",
    "Let's see how it goes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from searchtweets import collect_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tweets = collect_results(query,\n",
    "                         result_stream_args=v2_search_args) # change this if you need to"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, Tweet payloads are lazily parsed into a `Tweet` [object](https://twitterdev.github.io/tweet_parser/). An overwhelming number of Tweet attributes are made available directly, as such:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[print(tweet.all_text, end='\\n\\n') for tweet in tweets[0:10]];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[print(tweet.created_at_datetime) for tweet in tweets[0:10]];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[print(tweet.generator.get(\"name\")) for tweet in tweets[0:10]];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voila, we have some Tweets. For interactive environments and other cases where you don't care about collecting your data in a single load or don't need to operate on the stream of Tweets or counts directly, I recommend using this convenience function.\n",
    "\n",
    "\n",
    "## Working with the ResultStream\n",
    "\n",
    "The ResultStream object will be powered by the `search_args`, and takes the rules and other configuration parameters, including a hard stop on number of pages to limit your API call usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs = ResultStream(rule_payload=rule,\n",
    "                  max_results=500,\n",
    "                  max_pages=1,\n",
    "                  **premium_search_args)\n",
    "\n",
    "print(rs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a function, `.stream`, that seamlessly handles requests and pagination for a given query. It returns a generator, and to grab our 500 Tweets that mention `beyonce` we can do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweets = list(rs.stream())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tweets are lazily parsed using our [Tweet Parser](https://twitterdev.github.io/tweet_parser/), so tweet data is very easily extractable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using unidecode to prevent emoji/accents printing \n",
    "[print(tweet.all_text) for tweet in tweets[0:10]];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dated searches / Full Archive Search\n",
    "\n",
    "**Note that this will only work with the full archive search option**, which is available to my account only via the enterprise options. Full archive search will likely require a different endpoint or access method; please see your developer console for details.\n",
    "\n",
    "Let's make a new rule and pass it dates this time.\n",
    "\n",
    "`gen_rule_payload` takes timestamps of the following forms:\n",
    "\n",
    "\n",
    "- `YYYYmmDDHHMM`\n",
    "- `YYYY-mm-DD` (which will convert to midnight UTC (00:00)\n",
    "- `YYYY-mm-DD HH:MM`\n",
    "- `YYYY-mm-DDTHH:MM`\n",
    "\n",
    "Note - all Tweets are stored in UTC time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rule = gen_rule_payload(\"from:jack\",\n",
    "                        from_date=\"2017-09-01\", #UTC 2017-09-01 00:00\n",
    "                        to_date=\"2017-10-30\",#UTC 2017-10-30 00:00\n",
    "                        results_per_call=500)\n",
    "print(rule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweets = collect_results(rule, max_results=500, result_stream_args=enterprise_search_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[print(tweet.all_text) for tweet in tweets[0:10]];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = gen_request_parameters(\"from:jack\",\n",
    "                        from_date=\"2017-09-20\",\n",
    "                        to_date=\"2017-10-30\",\n",
    "                        count_bucket=\"day\",\n",
    "                        results_per_call=500)\n",
    "print(query)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('telegram')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "d2386c381fab908a4e48f3c5849d193fc799b9f792c037a48abb7a588aa93a14"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
